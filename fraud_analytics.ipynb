{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "479a7e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- step: integer (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- nameOrig: string (nullable = true)\n",
      " |-- oldbalanceOrg: double (nullable = true)\n",
      " |-- newbalanceOrig: double (nullable = true)\n",
      " |-- nameDest: string (nullable = true)\n",
      " |-- oldbalanceDest: double (nullable = true)\n",
      " |-- newbalanceDest: double (nullable = true)\n",
      " |-- isFraud: integer (nullable = true)\n",
      " |-- isFlaggedFraud: integer (nullable = true)\n",
      "\n",
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "|step|type    |amount  |nameOrig   |oldbalanceOrg|newbalanceOrig|nameDest   |oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|\n",
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "|1   |PAYMENT |9839.64 |C1231006815|170136.0     |160296.36     |M1979787155|0.0           |0.0           |0      |0             |\n",
      "|1   |PAYMENT |1864.28 |C1666544295|21249.0      |19384.72      |M2044282225|0.0           |0.0           |0      |0             |\n",
      "|1   |TRANSFER|181.0   |C1305486145|181.0        |0.0           |C553264065 |0.0           |0.0           |1      |0             |\n",
      "|1   |CASH_OUT|181.0   |C840083671 |181.0        |0.0           |C38997010  |21182.0       |0.0           |1      |0             |\n",
      "|1   |PAYMENT |11668.14|C2048537720|41554.0      |29885.86      |M1230701703|0.0           |0.0           |0      |0             |\n",
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FraudAnalytics\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "df_raw_sample = spark.read.csv(\"C:\\\\Users\\\\pradh\\\\Desktop\\\\archive (1)\\\\Synthetic_Financial_datasets_log.csv\", header=True, inferSchema=True)\n",
    "df_raw_sample.printSchema()\n",
    "df_raw_sample.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6806d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"step\", IntegerType(), True),\n",
    "    StructField(\"type\", StringType(), True),\n",
    "    StructField(\"amount\", DoubleType(), True),\n",
    "    StructField(\"nameOrig\", StringType(), True),\n",
    "    StructField(\"oldbalanceOrg\", DoubleType(), True),\n",
    "    StructField(\"newbalanceOrg\", DoubleType(), True),\n",
    "    StructField(\"nameDest\", StringType(), True),\n",
    "    StructField(\"oldbalanceDest\", DoubleType(), True),\n",
    "    StructField(\"newbalanceDest\", DoubleType(), True),\n",
    "    StructField(\"isFraud\", IntegerType(), True),\n",
    "    StructField(\"isFlaggedFraud\", IntegerType(), True),\n",
    "])\n",
    "\n",
    "df = spark.read.csv(\"C:\\\\Users\\\\pradh\\\\Desktop\\\\archive (1)\\\\Synthetic_Financial_datasets_log.csv\", header=True, schema=schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "722cbf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 6362620\n",
      "+--------+\n",
      "|    type|\n",
      "+--------+\n",
      "|TRANSFER|\n",
      "| CASH_IN|\n",
      "|CASH_OUT|\n",
      "| PAYMENT|\n",
      "|   DEBIT|\n",
      "+--------+\n",
      "\n",
      "+-------+-------+\n",
      "|isFraud|  count|\n",
      "+-------+-------+\n",
      "|      0|6354407|\n",
      "|      1|   8213|\n",
      "+-------+-------+\n",
      "\n",
      "+--------------+-------+\n",
      "|isFlaggedFraud|  count|\n",
      "+--------------+-------+\n",
      "|             0|6362604|\n",
      "|             1|     16|\n",
      "+--------------+-------+\n",
      "\n",
      "+----+----+------+--------+-------------+-------------+--------+--------------+--------------+-------+--------------+\n",
      "|step|type|amount|nameOrig|oldbalanceOrg|newbalanceOrg|nameDest|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|\n",
      "+----+----+------+--------+-------------+-------------+--------+--------------+--------------+-------+--------------+\n",
      "|   0|   0|     0|       0|            0|            0|       0|             0|             0|      0|             0|\n",
      "+----+----+------+--------+-------------+-------------+--------+--------------+--------------+-------+--------------+\n",
      "\n",
      "+-------+------------------+------------------+-----------------+------------------+------------------+\n",
      "|summary|            amount|     oldbalanceOrg|    newbalanceOrg|    oldbalanceDest|    newbalanceDest|\n",
      "+-------+------------------+------------------+-----------------+------------------+------------------+\n",
      "|  count|           6362620|           6362620|          6362620|           6362620|           6362620|\n",
      "|    min|               0.0|               0.0|              0.0|               0.0|               0.0|\n",
      "|    max|     9.244551664E7|     5.958504037E7|    4.958504037E7|    3.5601588935E8|    3.5617927892E8|\n",
      "|   mean|179861.90354913156| 833883.1040744876|855113.6685785913| 1100701.666519651|1224996.3982019257|\n",
      "| stddev| 603858.2314629381|2888242.6730375625|2924048.502954259|3399180.1129944725|3674128.9421196347|\n",
      "+-------+------------------+------------------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Row count\n",
    "total_rows = df.count(); print(\"rows:\", total_rows)\n",
    "\n",
    "# Distinct values & sanity of key columns\n",
    "df.select(\"type\").distinct().show(50)\n",
    "df.groupBy(\"isFraud\").count().orderBy(\"isFraud\").show()\n",
    "df.groupBy(\"isFlaggedFraud\").count().orderBy(\"isFlaggedFraud\").show()\n",
    "\n",
    "# Null counts column \n",
    "from pyspark.sql.functions import sum as _sum\n",
    "df.select([_sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns]).show()\n",
    "\n",
    "# Numeric summaries\n",
    "df.select(\"amount\",\"oldbalanceOrg\",\"newbalanceOrg\",\"oldbalanceDest\",\"newbalanceDest\").summary(\"count\",\"min\",\"max\",\"mean\",\"stddev\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b6fd69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg_amount: 0 neg_org: 0 neg_dest: 0\n",
      "exact_duplicate_rows: 0\n",
      "+-------+--------------+-------+\n",
      "|isFraud|isFlaggedFraud|  count|\n",
      "+-------+--------------+-------+\n",
      "|      0|             0|6354407|\n",
      "|      1|             0|   8197|\n",
      "|      1|             1|     16|\n",
      "+-------+--------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Negative checks\n",
    "neg_amount = df.filter(col(\"amount\") < 0).count()\n",
    "neg_org = df.filter((col(\"oldbalanceOrg\") < 0) | (col(\"newbalanceOrg\") < 0)).count()\n",
    "neg_dest = df.filter((col(\"oldbalanceDest\") < 0) | (col(\"newbalanceDest\") < 0)).count()\n",
    "print(\"neg_amount:\", neg_amount, \"neg_org:\", neg_org, \"neg_dest:\", neg_dest)\n",
    "\n",
    "# Duplicates\n",
    "dups = df.count() - df.dropDuplicates().count()\n",
    "print(\"exact_duplicate_rows:\", dups)\n",
    "\n",
    "# Weird flags\n",
    "df.groupBy(\"isFraud\",\"isFlaggedFraud\").count().orderBy(\"isFraud\",\"isFlaggedFraud\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d863573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning: 6362620\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_clean = df.dropDuplicates()\n",
    "\n",
    "print(\"After cleaning:\", df_clean.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e346e124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|isFraud|  count|\n",
      "+-------+-------+\n",
      "|      1|   8213|\n",
      "|      0|6354407|\n",
      "+-------+-------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|            amount|\n",
      "+-------+------------------+\n",
      "|  count|           6362620|\n",
      "|    min|               0.0|\n",
      "|    max|     9.244551664E7|\n",
      "|   mean|179861.90354913048|\n",
      "| stddev| 603858.2314629363|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fraud vs non-fraud \n",
    "df_clean.groupBy(\"isFraud\").count().show()\n",
    "\n",
    "# Amount summary\n",
    "df_clean.select(\"amount\").summary(\"count\",\"min\",\"max\",\"mean\",\"stddev\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a64138a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-----------+--------------------+-------------------+--------------+\n",
      "|    type|tx_count|fraud_count|        total_amount|       fraud_amount|fraud_rate_pct|\n",
      "+--------+--------+-----------+--------------------+-------------------+--------------+\n",
      "|TRANSFER|  532909|       4097|4.852919872631704E11|    6.06721318401E9|        0.7688|\n",
      "|CASH_OUT| 2237500|       4116|3.944129952244925E11|5.989202243829999E9|         0.184|\n",
      "| CASH_IN| 1399284|          0|2.363673919124594...|                0.0|           0.0|\n",
      "| PAYMENT| 2151495|          0|2.809337113836992...|                0.0|           0.0|\n",
      "|   DEBIT|   41432|          0|2.2719922127999997E8|                0.0|           0.0|\n",
      "+--------+--------+-----------+--------------------+-------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_clean.createOrReplaceTempView(\"transactions_clean\")                                             #HIVEQL type queries \n",
    "\n",
    "\n",
    "fraud_by_type = spark.sql(\"\"\"\n",
    "SELECT type,\n",
    "       COUNT(*) as tx_count,             \n",
    "       SUM(isFraud) as fraud_count,\n",
    "       SUM(amount) as total_amount,\n",
    "       SUM(CASE WHEN isFraud=1 THEN amount ELSE 0 END) as fraud_amount,\n",
    "       ROUND(SUM(isFraud)/COUNT(*)*100, 4) as fraud_rate_pct\n",
    "FROM transactions_clean\n",
    "GROUP BY type\n",
    "ORDER BY fraud_rate_pct DESC\n",
    "\"\"\")\n",
    "fraud_by_type.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97021fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-----------+--------------------+------------------+\n",
      "|step|tx_count|fraud_count|        total_amount|      fraud_amount|\n",
      "+----+--------+-----------+--------------------+------------------+\n",
      "|   1|    2708|         16|2.8542918115000004E8|3740247.0100000002|\n",
      "|   2|    1014|          8| 8.592160401999998E7|4186592.4800000004|\n",
      "|   3|     552|          4|4.3293884419999994E7|          66832.74|\n",
      "|   4|     565|         10| 7.291002857000001E7|      2.64002749E7|\n",
      "|   5|     665|          6|       4.554808975E7|         381841.54|\n",
      "|   6|    1660|         22|1.6431055121999997E8| 974869.6799999999|\n",
      "|   7|    6837|         12|      8.3293081424E8|     1.241469406E7|\n",
      "|   8|   21097|         12|3.4396024073500004E9|        1589040.41|\n",
      "|   9|   37628|         19| 7.008379239430001E9|     1.147663022E7|\n",
      "|  10|   35991|         11| 7.124214893709999E9|        6935977.72|\n",
      "+----+--------+-----------+--------------------+------------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "fraud_by_step = spark.sql(\"\"\"\n",
    "SELECT step,\n",
    "       COUNT(*) as tx_count,\n",
    "       SUM(isFraud) as fraud_count,\n",
    "       SUM(amount) as total_amount,\n",
    "       SUM(CASE WHEN isFraud=1 THEN amount ELSE 0 END) as fraud_amount\n",
    "FROM transactions_clean\n",
    "GROUP BY step\n",
    "ORDER BY step\n",
    "\"\"\")\n",
    "fraud_by_step.show(10)   # shows first 10 steps\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3175744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+-----------+------------+\n",
      "|   nameOrig|tx_count|fraud_count|fraud_amount|\n",
      "+-----------+--------+-----------+------------+\n",
      "|C1619838170|       1|          1|       1.0E7|\n",
      "|C1295280435|       1|          1|       1.0E7|\n",
      "| C525906402|       1|          1|       1.0E7|\n",
      "|C1677039996|       1|          1|       1.0E7|\n",
      "|C1552522980|       1|          1|       1.0E7|\n",
      "|C1853514800|       1|          1|       1.0E7|\n",
      "| C523152614|       1|          1|       1.0E7|\n",
      "| C819618584|       1|          1|       1.0E7|\n",
      "|C1930318116|       1|          1|       1.0E7|\n",
      "| C180127057|       1|          1|       1.0E7|\n",
      "|C1531278091|       1|          1|       1.0E7|\n",
      "|C1028530067|       1|          1|       1.0E7|\n",
      "|C1057439889|       1|          1|       1.0E7|\n",
      "|C1274141620|       1|          1|       1.0E7|\n",
      "|C1577275521|       1|          1|       1.0E7|\n",
      "|C1952386173|       1|          1|       1.0E7|\n",
      "| C179802055|       1|          1|       1.0E7|\n",
      "|C1041060645|       1|          1|       1.0E7|\n",
      "|C1721880478|       1|          1|       1.0E7|\n",
      "|C2087654131|       1|          1|       1.0E7|\n",
      "+-----------+--------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_orig = spark.sql(\"\"\"\n",
    "SELECT nameOrig,\n",
    "       COUNT(*) as tx_count,\n",
    "       SUM(isFraud) as fraud_count,\n",
    "       SUM(CASE WHEN isFraud=1 THEN amount ELSE 0 END) as fraud_amount\n",
    "FROM transactions_clean\n",
    "GROUP BY nameOrig\n",
    "ORDER BY fraud_amount DESC\n",
    "LIMIT 20\n",
    "\"\"\")\n",
    "top_orig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c354b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+-----------+-------------+\n",
      "|   nameDest|tx_count|fraud_count| fraud_amount|\n",
      "+-----------+--------+-----------+-------------+\n",
      "| C668046170|       5|          2|1.016008868E7|\n",
      "| C380259496|      24|          1|        1.0E7|\n",
      "|C1236804041|       1|          1|        1.0E7|\n",
      "|C1877706055|       3|          1|        1.0E7|\n",
      "| C574552283|      16|          1|        1.0E7|\n",
      "+-----------+--------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_dest = spark.sql(\"\"\"\n",
    "SELECT nameDest,\n",
    "       COUNT(*) as tx_count,\n",
    "       SUM(isFraud) as fraud_count,\n",
    "       SUM(CASE WHEN isFraud=1 THEN amount ELSE 0 END) as fraud_amount\n",
    "FROM transactions_clean\n",
    "GROUP BY nameDest\n",
    "ORDER BY fraud_amount DESC\n",
    "LIMIT 5\n",
    "\"\"\")\n",
    "top_dest.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c03c40a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+-------+\n",
      "|isFraud|isFlaggedFraud|    cnt|\n",
      "+-------+--------------+-------+\n",
      "|      0|             0|6354407|\n",
      "|      1|             0|   8197|\n",
      "|      1|             1|     16|\n",
      "+-------+--------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flag_vs_fraud = spark.sql(\"\"\"\n",
    "SELECT isFraud, isFlaggedFraud, COUNT(*) as cnt\n",
    "FROM transactions_clean\n",
    "GROUP BY isFraud, isFlaggedFraud\n",
    "ORDER BY isFraud, isFlaggedFraud\n",
    "\"\"\")\n",
    "flag_vs_fraud.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47adec86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+-----------+--------------------+--------------------+---------------------+\n",
      "|amount_bucket|tx_count|fraud_count|        total_amount|        fraud_amount|fraud_rate_percentage|\n",
      "+-------------+--------+-----------+--------------------+--------------------+---------------------+\n",
      "|          1M+|  130626|       2706|3.337635258004104E11|1.046072230895000...|               2.0716|\n",
      "|      100K-1M| 2706696|       3800|7.151167026037612E11|1.5226730667999997E9|               0.1404|\n",
      "|     10K-100K| 2239207|       1429|8.946644599596988E10| 7.181822573000002E7|               0.0638|\n",
      "|         0-1K|  142646|         58| 7.156829399000004E7|  14039.180000000002|               0.0407|\n",
      "|       1K-10K| 1143445|        220| 5.974702065639999E9|  1187787.1800000002|               0.0192|\n",
      "+-------------+--------+-----------+--------------------+--------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fraud_by_bucket = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  CASE \n",
    "    WHEN amount <= 1000 THEN '0-1K'\n",
    "    WHEN amount > 1000 AND amount <= 10000 THEN '1K-10K'\n",
    "    WHEN amount > 10000 AND amount <= 100000 THEN '10K-100K'\n",
    "    WHEN amount > 100000 AND amount <= 1000000 THEN '100K-1M'\n",
    "    ELSE '1M+'\n",
    "  END AS amount_bucket,\n",
    "  COUNT(*) AS tx_count,\n",
    "  SUM(isFraud) AS fraud_count,\n",
    "  SUM(amount) AS total_amount,\n",
    "  SUM(CASE WHEN isFraud=1 THEN amount ELSE 0 END) AS fraud_amount,\n",
    "  ROUND(SUM(isFraud)/COUNT(*)*100, 4) AS fraud_rate_percentage\n",
    "FROM transactions_clean\n",
    "GROUP BY\n",
    "  CASE \n",
    "    WHEN amount <= 1000 THEN '0-1K'\n",
    "    WHEN amount > 1000 AND amount <= 10000 THEN '1K-10K'\n",
    "    WHEN amount > 10000 AND amount <= 100000 THEN '10K-100K'\n",
    "    WHEN amount > 100000 AND amount <= 1000000 THEN '100K-1M'\n",
    "    ELSE '1M+'\n",
    "  END\n",
    "ORDER BY fraud_rate_percentage DESC\n",
    "\"\"\")\n",
    "\n",
    "fraud_by_bucket.show()\n",
    "fraud_by_bucket.toPandas().to_csv(\"fraud_by_bucket.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05c31302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+--------------+------------------------+\n",
      "|isFraud|transaction_count|mismatch_count|mismatch_rate_percentage|\n",
      "+-------+-----------------+--------------+------------------------+\n",
      "|      1|             8213|            45|                  0.5479|\n",
      "|      0|          6354407|       5077646|                 79.9075|\n",
      "+-------+-----------------+--------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean.createOrReplaceTempView(\"transactions_clean\")\n",
    "\n",
    "fraud_balance_stats = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    isFraud,\n",
    "    COUNT(*) AS transaction_count,\n",
    "    SUM(CASE WHEN ABS((oldbalanceOrg - amount) - newbalanceOrg) > 0.01 THEN 1 ELSE 0 END) AS mismatch_count,\n",
    "    ROUND(SUM(CASE WHEN ABS((oldbalanceOrg - amount) - newbalanceOrg) > 0.01 THEN 1 ELSE 0 END) / COUNT(*) * 100, 4) AS mismatch_rate_percentage\n",
    "FROM transactions_clean\n",
    "GROUP BY isFraud\n",
    "\"\"\")\n",
    "\n",
    "fraud_balance_stats.show()\n",
    "fraud_balance_stats.toPandas().to_csv(\"fraud_balance_stats.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e4a5535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+-----------+---------------------+\n",
      "|step|transaction_count|fraud_count|fraud_rate_percentage|\n",
      "+----+-----------------+-----------+---------------------+\n",
      "|   1|             2708|         16|               0.5908|\n",
      "|   2|             1014|          8|                0.789|\n",
      "|   3|              552|          4|               0.7246|\n",
      "|   4|              565|         10|               1.7699|\n",
      "|   5|              665|          6|               0.9023|\n",
      "|   6|             1660|         22|               1.3253|\n",
      "|   7|             6837|         12|               0.1755|\n",
      "|   8|            21097|         12|               0.0569|\n",
      "|   9|            37628|         19|               0.0505|\n",
      "|  10|            35991|         11|               0.0306|\n",
      "|  11|            37241|          7|               0.0188|\n",
      "|  12|            36153|         14|               0.0387|\n",
      "|  13|            37515|         14|               0.0373|\n",
      "|  14|            41485|         12|               0.0289|\n",
      "|  15|            44609|         20|               0.0448|\n",
      "|  16|            42471|         10|               0.0235|\n",
      "|  17|            43361|          7|               0.0161|\n",
      "|  18|            49579|         16|               0.0323|\n",
      "|  19|            51352|         11|               0.0214|\n",
      "|  20|            40625|          4|               0.0098|\n",
      "+----+-----------------+-----------+---------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "#fraud over time \n",
    "\n",
    "fraud_by_step = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    step,\n",
    "    COUNT(*) AS transaction_count,\n",
    "    SUM(isFraud) AS fraud_count,\n",
    "    ROUND(SUM(isFraud) / COUNT(*) * 100, 4) AS fraud_rate_percentage\n",
    "FROM transactions_clean\n",
    "GROUP BY step\n",
    "ORDER BY step\n",
    "\"\"\")\n",
    "\n",
    "fraud_by_step.show()\n",
    "fraud_by_step.toPandas().to_csv(\"fraud_by_step_trend.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0fb22a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+\n",
      "|amount    |freq|\n",
      "+----------+----+\n",
      "|1.0E7     |287 |\n",
      "|1165187.89|4   |\n",
      "|429257.45 |4   |\n",
      "|9996886.64|2   |\n",
      "|9977761.05|2   |\n",
      "|9960382.4 |2   |\n",
      "|9887819.06|2   |\n",
      "|9811104.49|2   |\n",
      "|9772559.35|2   |\n",
      "|9749042.95|2   |\n",
      "|9725837.08|2   |\n",
      "|9639524.7 |2   |\n",
      "|9639052.83|2   |\n",
      "|9593838.63|2   |\n",
      "|9468064.05|2   |\n",
      "|9465988.82|2   |\n",
      "|9453680.72|2   |\n",
      "|9421856.87|2   |\n",
      "|9345700.07|2   |\n",
      "|9301213.46|2   |\n",
      "+----------+----+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Fraud transactions with same non-zero amount repeated multiple times\n",
    "fraud_amount_repeats = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    amount,\n",
    "    COUNT(*) AS freq\n",
    "FROM transactions_clean\n",
    "WHERE isFraud = 1\n",
    "  AND amount > 0\n",
    "GROUP BY amount\n",
    "HAVING COUNT(*) > 1\n",
    "ORDER BY freq DESC, amount DESC\n",
    "\"\"\")\n",
    "\n",
    "fraud_amount_repeats.show(20, False)\n",
    "fraud_amount_repeats.toPandas().to_csv(\"fraud_amount_repeats.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8674142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------------+------------------+\n",
      "|   nameDest|fraud_transaction_count|fraud_total_amount|\n",
      "+-----------+-----------------------+------------------+\n",
      "| C668046170|                      2|     1.016008868E7|\n",
      "|C1595458981|                      1|             1.0E7|\n",
      "|C1622860679|                      1|             1.0E7|\n",
      "| C103172881|                      1|             1.0E7|\n",
      "|C1423246212|                      1|             1.0E7|\n",
      "| C709815552|                      1|             1.0E7|\n",
      "|C1806199534|                      1|             1.0E7|\n",
      "|C1270029603|                      1|             1.0E7|\n",
      "|C2065262017|                      1|             1.0E7|\n",
      "|C1732619349|                      1|             1.0E7|\n",
      "+-----------+-----------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # Top Fraud Destinations (Receivers)\n",
    "fraud_destinations = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    nameDest,\n",
    "    COUNT(*) AS fraud_transaction_count,\n",
    "    SUM(amount) AS fraud_total_amount\n",
    "FROM transactions_clean\n",
    "WHERE isFraud = 1\n",
    "GROUP BY nameDest\n",
    "ORDER BY fraud_total_amount DESC\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "fraud_destinations.show()\n",
    "fraud_destinations.toPandas().to_csv(\"fraud_destinations_by_amount.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d9f3071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+------------------+\n",
      "|isFraud|isFlaggedFraud|transactioon_count|\n",
      "+-------+--------------+------------------+\n",
      "|      1|             1|                16|\n",
      "|      1|             0|              8197|\n",
      "|      0|             0|           6354407|\n",
      "+-------+--------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Flagged vs Actual Fraud \n",
    "flag_vs_fraud = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    isFraud,\n",
    "    isFlaggedFraud,\n",
    "    COUNT(*) AS transactioon_count\n",
    "FROM transactions_clean\n",
    "GROUP BY isFraud, isFlaggedFraud\n",
    "ORDER BY isFraud DESC, isFlaggedFraud DESC\n",
    "\"\"\")\n",
    "\n",
    "flag_vs_fraud.show()\n",
    "flag_vs_fraud.toPandas().to_csv(\"flag_vs_fraud_analysis.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
